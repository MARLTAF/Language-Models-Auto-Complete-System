# Language-Models-Auto-Complete-System
This project builds an auto-complete system using N-gram language models. It processes Twitter data through tokenization and vocabulary filtering. The model applies k-smoothing to estimate word probabilities. Perplexity is used to evaluate model performance. Finally, it predicts the most likely next word for any given sentence.
